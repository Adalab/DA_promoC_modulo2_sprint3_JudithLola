{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pair Programming ETL Transformación I\n",
    "### Modulo 2 Sprint 2\n",
    "#### Lola Rubio y Judith Mellidez \n",
    "\n",
    "Tendréis que usar el csv attacks_limpieza_completa que tenéis adjunto abajo.\n",
    "\n",
    "En la lección de hoy aprendimos como transformar nuestros datos para que estén preparados para almacearlos en una BBDD. En este momento tenemos dos fuentes de datos:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. El csv con los ataques de tiburones que hemos estado limpiando hasta ahora, el que os hemos adjuntado (attacks_limpieza_completa). Sentiros libres de usar vuestros propios csv en caso de que queráis.\n",
    "2. El csv con los datos climáticos de los principales paises que tienen ataques de tiburones, el que creamos en el pair programming de ayer.\n",
    "\n",
    "El objetivo de la sesión de hoy será juntar en un único csv la información de ambas fuentes. Para ello:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cargaremos los dos ficheros de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Del dataframe de los ataques nos quedaremos solo con las filas de los países que seleccionamos en la lección de ayer:\n",
    "    - USA\n",
    "    - Australia\n",
    "    - New Zealand\n",
    "    - South Africa\n",
    "    - Papua New Guinea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Del dataframe de los datos climáticos seleccionaremos todas las columnas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cuando ya tengamos todos los datos deseados juntaremos los dos csv.\n",
    "    - Para hacer esta unión tendremos que hacer un groupby en la tabla de clima para sacar una media de las medidas climáticas por país.\n",
    "    \n",
    "    - Para hacer esta unión tendremos que hacer un groupby en la tabla de clima para sacar una media de las medidas climáticas por país.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os recomendamos resetear el index del dataframe de los datos climáticos para que no se repitan los nombres de las columnas.\n",
    "\n",
    "\n",
    "# El primer problema al que nos podemos enfrentar es que si vemos los tipos de las columnas vemos que estas columnas son objetos, es decir, strings, lo que hará que trabajar con ellas sea un poco complicado: \n",
    "clima.dtypes\n",
    "\n",
    "timepoint             int64\n",
    "cloudcover            int64\n",
    "highcloud             int64\n",
    "midcloud              int64\n",
    "lowcloud              int64\n",
    "rh_profile           object\n",
    "wind_profile         object\n",
    "\n",
    "# en Python tenemos la librería `ast` que nos permite castear un string que dentro tiene diccionarios, o listas o tuplas a su tipo correspondiente. En nuestro caso, lo que conseguiremos es no tener strings sino listas en la columna. Esto lo haremos de la siguiente forma: \n",
    "\n",
    "import ast\n",
    "\n",
    "clima['wind_profile']= clima['wind_profile'].apply(ast.literal_eval)\n",
    "\n",
    "# una vez que tengamos la columna cambiada, una fantasía de Pandas es que si hago un apply sobre una columna cuyos valores son diccionarios o listas nos va a genererar una columna con los valores de los diccionarios o listas. Donde cada columna será key del diccionario o cada elemento de la lista. \n",
    "\n",
    "\n",
    "x = clima['wind_profile'].apply(pd.Series)\n",
    "\n",
    "\n",
    "# nos creamos un dataframe nuevo con el resultado de la información de una de las columnas separadas por columnas. Esto nos va a devolver un dataframe donde cada fila será una celda del dataframe anterior. \n",
    "x = df['rh_profile'].apply(pd.Series) \n",
    "\n",
    "# ¿Qué es lo que ocurre cuando hacemos esto?\n",
    "# Nos ha creado tantas columnas como valores tuvieramos en la lista. Donde columna es, en este caso, un diccionario (porque nuestra lista esta compuesta por distintos diccionarios)\n",
    "\n",
    "# Ok, hemos conseguido desempaquetar la información de la lista en distintas columnas. Ahora tenemos que despempaquetar la información de los diccionarios en distintas columnas. En este caso, lo que querremos es que las key de los diccionarios sean los nombres de las columnas y los values los valores de las celdas del dataframe. Volveremos a seguir entonces la misma lógica que antes con el apply, pero en este caso necesitamos hacerlo para todo el dataframe (que es x): \n",
    "\n",
    "# Por eso empezamos con un for para iterar por cada una de las columnas. \n",
    "for i in range(len(x.columns)): \n",
    "\n",
    "    # aplicamos el apply,extraemos el valore de la key \"layer\" y lo almacenamos en una variable que convertimos a string \n",
    "    nombre = \"rh_\" + str(x[i].apply(pd.Series)[\"layer\"][0]) \n",
    "\n",
    "    # hacemos lo mismo con una variable que se llame valores para \"guardar\" los valores de la celda\n",
    "    valores = list(x[i].apply(pd.Series)[\"rh\"] )\n",
    "\n",
    "    # usamos el método insert de los dataframes para ir añadiendo esta información a el dataframe con la información del clima. \n",
    "    df.insert(i, nombre, valores)\n",
    "\n",
    "# una vez que hayamos hecho esto para las dos columnas ya podremos hacer el gropuby para después unir toda la información. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Guardar los resultados obtenidos en un csv que usaremos en próximos ejercicios de pair programming."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.9 (default, Jun 29 2022, 11:45:57) \n[GCC 8.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
